{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64727\n",
      "64727\n",
      "158538\n",
      "8898\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import glob\n",
    "\n",
    "files = glob.glob('/home/freinque/cours/voice/sillytalks/data/pickles/train/*.p')\n",
    "print len(files)\n",
    "files = glob.glob('/home/freinque/cours/voice/sillytalks/data/pickles/pipeline_train/*.p')\n",
    "print len(files)\n",
    "\n",
    "files = glob.glob('/home/freinque/cours/voice/sillytalks/data/pickles/test/*.p')\n",
    "print len(files)\n",
    "files = glob.glob('/home/freinque/cours/voice/sillytalks/data/pickles/pipeline_test/*.p')\n",
    "print len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br><br>\n",
    "# generate train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import glob\n",
    "\n",
    "files = glob.glob('/home/freinque/cours/voice/sillytalks/data/pickles/pipeline_train/*.p')\n",
    "\n",
    "Y_train = []\n",
    "\n",
    "for f in files[:1000]:\n",
    "\n",
    "        target = os.path.basename(f).split('_')[0]\n",
    "    \n",
    "        Y_train.append(target)\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "labels = list(np.sort(np.unique(Y_train)))\n",
    "\n",
    "pickle.dump( labels, open( '/home/freinque/cours/voice/sillytalks/data/labels.p', \"wt\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import glob\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def batch_generator(files, labels, batch_size, num_classes):\n",
    "\n",
    "\n",
    "    while True:\n",
    "        #print 'generator called: '\n",
    "        X_train = []\n",
    "        Y_train = []\n",
    "    \n",
    "        fil = np.random.choice(files, batch_size)\n",
    "        #print fil\n",
    "        for f in fil:\n",
    "\n",
    "            target = os.path.basename(f).split('_')[0]\n",
    "            feat = pickle.load( open(f, 'rb'))\n",
    "    \n",
    "            X_train.append( np.array([ np.array(feat) ]) )\n",
    "            Y_train.append(target)\n",
    "            \n",
    "        X_train = np.array(X_train)\n",
    "        #print 'X_train.shape', X_train.shape\n",
    "        \n",
    "        Y_train = np.array(Y_train)\n",
    "        Y_train = np.array( [ labels.index(y) for y in Y_train ] )\n",
    "        Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    "        #print 'Y_train.shpe', Y_train.shape\n",
    "        \n",
    "        yield X_train, Y_train\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 41, 615)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 41, 615)       832       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 41, 615)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 41, 615)       25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 8, 615)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29520)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3778688   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                3870      \n",
      "=================================================================\n",
      "Total params: 3,825,534\n",
      "Trainable params: 3,825,534\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "\n",
    "num_classes = 30\n",
    "\n",
    "    # layers\n",
    "conv_55_1 = Conv2D(32, (5, 5), padding='same', activation='relu', kernel_constraint=maxnorm(3), data_format=\"channels_first\")\n",
    "dropout_20 = Dropout(0.2)\n",
    "conv_55_2 = Conv2D(32, (5, 5), activation='relu', padding='same', kernel_constraint=maxnorm(3), data_format=\"channels_first\")\n",
    "max_pooling = MaxPooling2D(pool_size=(5, 5))\n",
    "\n",
    "flatten = Flatten()\n",
    "\n",
    "dense_128_1 = Dense(128, activation='relu', kernel_constraint=maxnorm(3))\n",
    "dense_128_2 = Dense(128, activation='relu', kernel_constraint=maxnorm(3))\n",
    "dropout_50 = Dropout(0.5)\n",
    "final_layer = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    # model\n",
    "inp = Input(shape=(1,41, 615))\n",
    "out = final_layer(dropout_50(dense_128_2(dense_128_1(flatten(max_pooling(conv_55_2(dropout_20(conv_55_1(inp)))))))))\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "    # Compile model\n",
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model_name = 'base_1'\n",
    "model_path = '/home/freinque/cours/voice/sillytalks/data/models'\n",
    "model.load_weights(os.path.join(model_path, model_name+'.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/50 [============================>.] - ETA: 38s - loss: 3.3889 - acc: 0.0446 Epoch 00001: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 2068s 41s/step - loss: 3.3889 - acc: 0.0438 - val_loss: 3.3524 - val_acc: 0.0469\n",
      "Epoch 2/10\n",
      "49/50 [============================>.] - ETA: 34s - loss: 3.2641 - acc: 0.0880 Epoch 00002: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 2045s 41s/step - loss: 3.2633 - acc: 0.0887 - val_loss: 3.0109 - val_acc: 0.1625\n",
      "Epoch 3/10\n",
      "49/50 [============================>.] - ETA: 58s - loss: 3.0584 - acc: 0.1288 Epoch 00003: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 3246s 65s/step - loss: 3.0578 - acc: 0.1281 - val_loss: 2.8668 - val_acc: 0.1562\n",
      "Epoch 4/10\n",
      "49/50 [============================>.] - ETA: 58s - loss: 2.8318 - acc: 0.1792 Epoch 00004: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 3236s 65s/step - loss: 2.8262 - acc: 0.1800 - val_loss: 2.6967 - val_acc: 0.2313\n",
      "Epoch 5/10\n",
      "49/50 [============================>.] - ETA: 58s - loss: 2.7331 - acc: 0.2168 Epoch 00005: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 3227s 65s/step - loss: 2.7276 - acc: 0.2194 - val_loss: 2.3918 - val_acc: 0.2844\n",
      "Epoch 6/10\n",
      "49/50 [============================>.] - ETA: 38s - loss: 2.5896 - acc: 0.2519 Epoch 00006: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 2131s 43s/step - loss: 2.5870 - acc: 0.2525 - val_loss: 2.3197 - val_acc: 0.3125\n",
      "Epoch 7/10\n",
      "49/50 [============================>.] - ETA: 28s - loss: 2.4998 - acc: 0.2781Epoch 00007: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 1528s 31s/step - loss: 2.5135 - acc: 0.2781 - val_loss: 2.2919 - val_acc: 0.3312\n",
      "Epoch 8/10\n",
      "49/50 [============================>.] - ETA: 23s - loss: 2.4283 - acc: 0.2857Epoch 00008: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 1408s 28s/step - loss: 2.4234 - acc: 0.2881 - val_loss: 2.0349 - val_acc: 0.4250\n",
      "Epoch 9/10\n",
      "49/50 [============================>.] - ETA: 25s - loss: 2.2462 - acc: 0.3323Epoch 00009: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 1673s 33s/step - loss: 2.2483 - acc: 0.3312 - val_loss: 2.0460 - val_acc: 0.4219\n",
      "Epoch 10/10\n",
      "29/50 [================>.............] - ETA: 21:29 - loss: 2.2307 - acc: 0.3351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/freinque/anaconda2/lib/python2.7/site-packages/keras/utils/data_utils.py\", line 635, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"<ipython-input-1-44a19de801f6>\", line 33, in batch_generator\n",
      "    Y_train = np.array( [ labels.index(y) for y in Y_train ] )\n",
      "ValueError: '' is not in list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/50 [===================>..........] - ETA: 16:07 - loss: 2.2486 - acc: 0.3355"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-46826492feab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m )\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/six.pyc\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: '' is not in list"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_name = 'base_1'\n",
    "model_path = '/home/freinque/cours/voice/sillytalks/data/models'\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(model_path, model_name+'.hdf5'), verbose=1, save_best_only=False)\n",
    "\n",
    "files = glob.glob('/home/freinque/cours/voice/sillytalks/data/pickles/pipeline_train/*.p')\n",
    "labels = pickle.load(open('/home/freinque/cours/voice/sillytalks/data/labels.p', 'rb'))\n",
    "batch_size = 32\n",
    "\n",
    "model.fit_generator(\n",
    "    batch_generator(files, labels, batch_size, num_classes), \n",
    "    validation_data = batch_generator(files, labels, batch_size, num_classes),\n",
    "    validation_steps = 10,\n",
    "    steps_per_epoch=50, \n",
    "    epochs=10,\n",
    "    workers=4, use_multiprocessing=True,\n",
    "    callbacks=[checkpointer,],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/50 [============================>.] - ETA: 42s - loss: 2.1415 - acc: 0.3731 Epoch 00001: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 2348s 47s/step - loss: 2.1416 - acc: 0.3725 - val_loss: 2.1273 - val_acc: 0.4406\n",
      "Epoch 2/10\n",
      "49/50 [============================>.] - ETA: 41s - loss: 2.1866 - acc: 0.3616 Epoch 00002: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 2276s 46s/step - loss: 2.1910 - acc: 0.3581 - val_loss: 2.0377 - val_acc: 0.3906\n",
      "Epoch 3/10\n",
      "49/50 [============================>.] - ETA: 39s - loss: 2.0246 - acc: 0.4005 Epoch 00003: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 2181s 44s/step - loss: 2.0230 - acc: 0.4012 - val_loss: 1.8998 - val_acc: 0.4594\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/freinque/anaconda2/lib/python2.7/site-packages/keras/utils/data_utils.py\", line 635, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"<ipython-input-1-44a19de801f6>\", line 29, in batch_generator\n",
      "    X_train = np.array(X_train)\n",
      "ValueError: could not broadcast input array from shape (41,615) into shape (1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/50 [==>...........................] - ETA: 34:03 - loss: 2.1609 - acc: 0.3812"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (41,615) into shape (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-46826492feab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m )\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/six.pyc\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (41,615) into shape (1)"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_name = 'base_1'\n",
    "model_path = '/home/freinque/cours/voice/sillytalks/data/models'\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(model_path, model_name+'.hdf5'), verbose=1, save_best_only=False)\n",
    "\n",
    "files = glob.glob('/home/freinque/cours/voice/sillytalks/data/pickles/pipeline_train/*.p')\n",
    "labels = pickle.load(open('/home/freinque/cours/voice/sillytalks/data/labels.p', 'rb'))\n",
    "batch_size = 32\n",
    "\n",
    "model.fit_generator(\n",
    "    batch_generator(files, labels, batch_size, num_classes), \n",
    "    validation_data = batch_generator(files, labels, batch_size, num_classes),\n",
    "    validation_steps = 10,\n",
    "    steps_per_epoch=50, \n",
    "    epochs=10,\n",
    "    workers=4, use_multiprocessing=True,\n",
    "    callbacks=[checkpointer,],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/50 [============================>.] - ETA: 43s - loss: 2.0627 - acc: 0.3909 Epoch 00001: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 2403s 48s/step - loss: 2.0543 - acc: 0.3925 - val_loss: 1.6597 - val_acc: 0.5563\n",
      "Epoch 2/10\n",
      "49/50 [============================>.] - ETA: 41s - loss: 1.9225 - acc: 0.4145 Epoch 00002: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 2341s 47s/step - loss: 1.9209 - acc: 0.4144 - val_loss: 1.7342 - val_acc: 0.5250\n",
      "Epoch 3/10\n",
      "49/50 [============================>.] - ETA: 44s - loss: 1.9252 - acc: 0.4267 Epoch 00003: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 2502s 50s/step - loss: 1.9310 - acc: 0.4263 - val_loss: 1.6783 - val_acc: 0.4750\n",
      "Epoch 4/10\n",
      "49/50 [============================>.] - ETA: 45s - loss: 1.8765 - acc: 0.4407 Epoch 00004: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 2519s 50s/step - loss: 1.8744 - acc: 0.4419 - val_loss: 1.6294 - val_acc: 0.5125\n",
      "Epoch 5/10\n",
      "49/50 [============================>.] - ETA: 44s - loss: 1.8072 - acc: 0.4649 Epoch 00005: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 2492s 50s/step - loss: 1.8069 - acc: 0.4656 - val_loss: 1.6649 - val_acc: 0.5531\n",
      "Epoch 6/10\n",
      "49/50 [============================>.] - ETA: 46s - loss: 1.7659 - acc: 0.4707 Epoch 00006: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 2444s 49s/step - loss: 1.7620 - acc: 0.4713 - val_loss: 1.5576 - val_acc: 0.5500\n",
      "Epoch 7/10\n",
      "49/50 [============================>.] - ETA: 2:35 - loss: 1.7692 - acc: 0.4707Epoch 00007: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 7725s 155s/step - loss: 1.7723 - acc: 0.4706 - val_loss: 1.5125 - val_acc: 0.5531\n",
      "Epoch 8/10\n",
      " 1/50 [..............................] - ETA: 9:54 - loss: 1.7789 - acc: 0.5000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-46826492feab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m )\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/freinque/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_name = 'base_1'\n",
    "model_path = '/home/freinque/cours/voice/sillytalks/data/models'\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(model_path, model_name+'.hdf5'), verbose=1, save_best_only=False)\n",
    "\n",
    "files = glob.glob('/home/freinque/cours/voice/sillytalks/data/pickles/pipeline_train/*.p')\n",
    "labels = pickle.load(open('/home/freinque/cours/voice/sillytalks/data/labels.p', 'rb'))\n",
    "batch_size = 32\n",
    "\n",
    "model.fit_generator(\n",
    "    batch_generator(files, labels, batch_size, num_classes), \n",
    "    validation_data = batch_generator(files, labels, batch_size, num_classes),\n",
    "    validation_steps = 10,\n",
    "    steps_per_epoch=50, \n",
    "    epochs=10,\n",
    "    workers=4, use_multiprocessing=True,\n",
    "    callbacks=[checkpointer,],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/50 [============================>.] - ETA: 13s - loss: 1.6908 - acc: 0.4853Epoch 00001: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 764s 15s/step - loss: 1.6934 - acc: 0.4862 - val_loss: 1.5176 - val_acc: 0.5844\n",
      "Epoch 2/10\n",
      "49/50 [============================>.] - ETA: 12s - loss: 1.6612 - acc: 0.5128Epoch 00002: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 667s 13s/step - loss: 1.6721 - acc: 0.5112 - val_loss: 1.3594 - val_acc: 0.5813\n",
      "Epoch 3/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.6120 - acc: 0.5159Epoch 00003: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 658s 13s/step - loss: 1.6133 - acc: 0.5188 - val_loss: 1.4513 - val_acc: 0.6000\n",
      "Epoch 4/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.5737 - acc: 0.5319Epoch 00004: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 657s 13s/step - loss: 1.5727 - acc: 0.5306 - val_loss: 1.4352 - val_acc: 0.5563\n",
      "Epoch 5/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.5473 - acc: 0.5421Epoch 00005: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 667s 13s/step - loss: 1.5431 - acc: 0.5419 - val_loss: 1.3079 - val_acc: 0.6250\n",
      "Epoch 6/10\n",
      "49/50 [============================>.] - ETA: 12s - loss: 1.5534 - acc: 0.5376Epoch 00006: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 667s 13s/step - loss: 1.5456 - acc: 0.5394 - val_loss: 1.4147 - val_acc: 0.5719\n",
      "Epoch 7/10\n",
      "49/50 [============================>.] - ETA: 12s - loss: 1.5359 - acc: 0.5230Epoch 00007: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 666s 13s/step - loss: 1.5369 - acc: 0.5238 - val_loss: 1.3173 - val_acc: 0.6531\n",
      "Epoch 8/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.5018 - acc: 0.5415Epoch 00008: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 657s 13s/step - loss: 1.5061 - acc: 0.5406 - val_loss: 1.1973 - val_acc: 0.6281\n",
      "Epoch 9/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.5152 - acc: 0.5587Epoch 00009: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 658s 13s/step - loss: 1.5040 - acc: 0.5600 - val_loss: 1.2179 - val_acc: 0.6219\n",
      "Epoch 10/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.3960 - acc: 0.5823Epoch 00010: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 659s 13s/step - loss: 1.3967 - acc: 0.5819 - val_loss: 1.1390 - val_acc: 0.6469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2290a2c6d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_name = 'base_1'\n",
    "model_path = '/home/freinque/cours/voice/sillytalks/data/models'\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(model_path, model_name+'.hdf5'), verbose=1, save_best_only=False)\n",
    "\n",
    "files = glob.glob('/home/freinque/cours/voice/sillytalks/data/pickles/pipeline_train/*.p')\n",
    "labels = pickle.load(open('/home/freinque/cours/voice/sillytalks/data/labels.p', 'rb'))\n",
    "batch_size = 32\n",
    "\n",
    "model.fit_generator(\n",
    "    batch_generator(files, labels, batch_size, num_classes), \n",
    "    validation_data = batch_generator(files, labels, batch_size, num_classes),\n",
    "    validation_steps = 10,\n",
    "    steps_per_epoch=50, \n",
    "    epochs=10,\n",
    "    workers=4, use_multiprocessing=True,\n",
    "    callbacks=[checkpointer,],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/50 [============================>.] - ETA: 12s - loss: 1.4185 - acc: 0.5804Epoch 00001: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 665s 13s/step - loss: 1.4151 - acc: 0.5831 - val_loss: 1.2898 - val_acc: 0.6562\n",
      "Epoch 2/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.4496 - acc: 0.5619Epoch 00002: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 659s 13s/step - loss: 1.4438 - acc: 0.5637 - val_loss: 1.2952 - val_acc: 0.6469\n",
      "Epoch 3/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.4042 - acc: 0.5842Epoch 00003: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 659s 13s/step - loss: 1.4072 - acc: 0.5844 - val_loss: 1.1547 - val_acc: 0.6719\n",
      "Epoch 4/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.3486 - acc: 0.5982Epoch 00004: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 656s 13s/step - loss: 1.3561 - acc: 0.5963 - val_loss: 1.1366 - val_acc: 0.6937\n",
      "Epoch 5/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.3398 - acc: 0.6052Epoch 00005: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 659s 13s/step - loss: 1.3472 - acc: 0.6025 - val_loss: 1.0130 - val_acc: 0.6969\n",
      "Epoch 6/10\n",
      "49/50 [============================>.] - ETA: 12s - loss: 1.4420 - acc: 0.5580Epoch 00006: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 669s 13s/step - loss: 1.4352 - acc: 0.5600 - val_loss: 1.2122 - val_acc: 0.6438\n",
      "Epoch 7/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.2649 - acc: 0.6218Epoch 00007: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 659s 13s/step - loss: 1.2608 - acc: 0.6225 - val_loss: 0.9749 - val_acc: 0.7063\n",
      "Epoch 8/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.2955 - acc: 0.6199Epoch 00008: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 659s 13s/step - loss: 1.2935 - acc: 0.6200 - val_loss: 1.1868 - val_acc: 0.6469\n",
      "Epoch 9/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.3318 - acc: 0.5963Epoch 00009: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 657s 13s/step - loss: 1.3341 - acc: 0.5963 - val_loss: 1.0432 - val_acc: 0.7000\n",
      "Epoch 10/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.2505 - acc: 0.6142Epoch 00010: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 658s 13s/step - loss: 1.2457 - acc: 0.6156 - val_loss: 0.9953 - val_acc: 0.7375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2291645610>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_name = 'base_1'\n",
    "model_path = '/home/freinque/cours/voice/sillytalks/data/models'\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(model_path, model_name+'.hdf5'), verbose=1, save_best_only=False)\n",
    "\n",
    "files = glob.glob('/home/freinque/cours/voice/sillytalks/data/pickles/pipeline_train/*.p')\n",
    "labels = pickle.load(open('/home/freinque/cours/voice/sillytalks/data/labels.p', 'rb'))\n",
    "batch_size = 32\n",
    "\n",
    "model.fit_generator(\n",
    "    batch_generator(files, labels, batch_size, num_classes), \n",
    "    validation_data = batch_generator(files, labels, batch_size, num_classes),\n",
    "    validation_steps = 10,\n",
    "    steps_per_epoch=50, \n",
    "    epochs=10,\n",
    "    workers=4, use_multiprocessing=True,\n",
    "    callbacks=[checkpointer,],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/50 [============================>.] - ETA: 15s - loss: 1.2409 - acc: 0.6224Epoch 00001: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 864s 17s/step - loss: 1.2438 - acc: 0.6206 - val_loss: 1.0429 - val_acc: 0.7188\n",
      "Epoch 2/10\n",
      "49/50 [============================>.] - ETA: 12s - loss: 1.2609 - acc: 0.6154Epoch 00002: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 663s 13s/step - loss: 1.2586 - acc: 0.6162 - val_loss: 1.0863 - val_acc: 0.6906\n",
      "Epoch 3/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.2408 - acc: 0.6295Epoch 00003: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 665s 13s/step - loss: 1.2421 - acc: 0.6281 - val_loss: 0.8814 - val_acc: 0.7625\n",
      "Epoch 4/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.2135 - acc: 0.6301Epoch 00004: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 662s 13s/step - loss: 1.2148 - acc: 0.6300 - val_loss: 1.1284 - val_acc: 0.6813\n",
      "Epoch 5/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.2128 - acc: 0.6333Epoch 00005: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 661s 13s/step - loss: 1.2099 - acc: 0.6338 - val_loss: 1.0165 - val_acc: 0.7063\n",
      "Epoch 6/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.1187 - acc: 0.6499Epoch 00006: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 665s 13s/step - loss: 1.1299 - acc: 0.6481 - val_loss: 0.9677 - val_acc: 0.7063\n",
      "Epoch 7/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.2069 - acc: 0.6263Epoch 00007: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 661s 13s/step - loss: 1.2015 - acc: 0.6269 - val_loss: 0.8934 - val_acc: 0.7500\n",
      "Epoch 8/10\n",
      "49/50 [============================>.] - ETA: 12s - loss: 1.1828 - acc: 0.6511Epoch 00008: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 662s 13s/step - loss: 1.1782 - acc: 0.6519 - val_loss: 0.9754 - val_acc: 0.6781\n",
      "Epoch 9/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.2334 - acc: 0.6480Epoch 00009: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 658s 13s/step - loss: 1.2350 - acc: 0.6481 - val_loss: 1.0073 - val_acc: 0.7375\n",
      "Epoch 10/10\n",
      "49/50 [============================>.] - ETA: 11s - loss: 1.1374 - acc: 0.6658Epoch 00010: saving model to /home/freinque/cours/voice/sillytalks/data/models/base_1.hdf5\n",
      "50/50 [==============================] - 659s 13s/step - loss: 1.1424 - acc: 0.6613 - val_loss: 0.8556 - val_acc: 0.7250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22912af8d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_name = 'base_1'\n",
    "model_path = '/home/freinque/cours/voice/sillytalks/data/models'\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(model_path, model_name+'.hdf5'), verbose=1, save_best_only=False)\n",
    "\n",
    "files = glob.glob('/home/freinque/cours/voice/sillytalks/data/pickles/pipeline_train/*.p')\n",
    "labels = pickle.load(open('/home/freinque/cours/voice/sillytalks/data/labels.p', 'rb'))\n",
    "batch_size = 32\n",
    "\n",
    "model.fit_generator(\n",
    "    batch_generator(files, labels, batch_size, num_classes), \n",
    "    validation_data = batch_generator(files, labels, batch_size, num_classes),\n",
    "    validation_steps = 10,\n",
    "    steps_per_epoch=50, \n",
    "    epochs=10,\n",
    "    workers=4, use_multiprocessing=True,\n",
    "    callbacks=[checkpointer,],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "class save_weights(Callback):\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        \n",
    "\n",
    "\n",
    "model.fit(\n",
    "          X_train[:int(0.8*len(X_train))], Y_train[:int(0.8*len(X_train))], \n",
    "          validation_data=(X_train[int(0.8*len(X_train)):], Y_train[int(0.8*len(X_train)):]), \n",
    "          epochs=epochs, \n",
    "          batch_size=32,\n",
    "          callbacks=[checkpointer,],\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_train[0.8*len(X_train):], Y_train[0.8*len(X_train):], verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(3, 32, 32), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# Compile model\n",
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
